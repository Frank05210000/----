import requests
import pandas as pd
from bs4 import BeautifulSoup
from io import StringIO
import urllib3
from tabulate import tabulate
import json

# é—œé–‰ SSL è­¦å‘Š
urllib3.disable_warnings()

# æ˜ å°„è¡¨
DAY_MAP = {'æ—¥':None,'ä¸€':'1','äºŒ':'2','ä¸‰':'3','å››':'4','äº”':'5','å…­':None}
PERIOD_MAP = {str(i): str(i) for i in range(1, 10)}
PERIOD_MAP.update({'10':'a', '11':'b'})  # è‹¥æœ‰æ›´å¤šï¼Œå¯å†åŠ  {'12':'c'}

# åè½‰ day_map ç”¨æ–¼ DataFrame æ¬„ä½
DAY_NUM_TO_COL = {v:k for k,v in DAY_MAP.items() if v}

def sort_key(code):
    """æŠŠæ™‚é–“ç¢¼ï¼ˆå¦‚ '1a'ã€'23'ï¼‰è½‰æˆå¯æ¯”å¤§å°çš„æ•´æ•¸ã€‚"""
    d, p = int(code[0]), code[1]
    idx = int(p) if p.isdigit() else (10 if p=='a' else 11)
    return d * 100 + idx

# æ–°å¢ï¼šå¿…é¸ä¿®ç¬¦è™Ÿå°ç…§
SYMBOL_MAP = {
    'â—‹': {'req': 'å¿…ä¿®', 'detail': 'éƒ¨è¨‚å…±åŒå¿…ä¿®'},
    'â–³': {'req': 'å¿…ä¿®', 'detail': 'æ ¡è¨‚å…±åŒå¿…ä¿®'},
    'â˜†': {'req': 'é¸ä¿®', 'detail': 'å…±åŒé¸ä¿®'},
    'â—': {'req': 'å¿…ä¿®', 'detail': 'éƒ¨è¨‚å°ˆæ¥­å¿…ä¿®'},
    'â–²': {'req': 'å¿…ä¿®', 'detail': 'æ ¡è¨‚å°ˆæ¥­å¿…ä¿®'},
    'â˜…': {'req': 'é¸ä¿®', 'detail': 'å°ˆæ¥­é¸ä¿®'},
}

def fetch_course_map(url):
    """
    input:ã€Œç­ç´šé é¢ã€æˆ–ã€Œç§‘ç³»é é¢ã€URLã€‚
    return: (label, course_map)
    course_map: {
      'èª²ç¨‹åç¨±': {
         'èª²è™Ÿ': .., 'æ•™å¸«': .., 'time_codes': [..],
         'symbol': 'â–²', 'req': 'å¿…ä¿®', 'detail': 'æ ¡è¨‚å°ˆæ¥­å¿…ä¿®'
      }
    }
    """
    resp = requests.get(url, headers={"User-Agent":"Mozilla/5.0"}, verify=False)
    resp.encoding = "utf-8"
    soup = BeautifulSoup(resp.text, "html.parser")

    # å–æ¨™é¡Œæœ€å¾Œçš„ã€Œ-- XXXã€æˆ–ã€Œã€€XXXã€
    header = soup.find("h2").get_text()
    label = header.split("--")[-1].strip()

    # æŠŠ HTML æŠ•çµ¦ pandas è®€å–è¡¨æ ¼
    try:
        df = pd.read_html(StringIO(resp.text), header=[0,1])[0]
    except ValueError:
        return label, {}

    # ä¿ç•™ç¬¬äºŒå±¤ header
    df.columns = df.columns.get_level_values(1)
    # éæ¿¾ç„¡èª²è™Ÿã€å°è¨ˆ
    df = df[df['èª²è™Ÿ'].notna() & (df['èª²è™Ÿ']!='å°è¨ˆ')].reset_index(drop=True)

    # è§£ææ™‚é–“ç¢¼èˆ‡ç¬¦è™Ÿ
    course_map = {}
    for _, row in df.iterrows():
        name    = row['èª²ç¨‹åç¨±']
        symbol  = str(row['ä¿®']).strip()  # â—‹ã€â–³ã€â˜†ã€â—ã€â–²ã€â˜…
        info    = SYMBOL_MAP.get(symbol, {'req': None, 'detail': None})
        codes   = []
        for day, dnum in DAY_MAP.items():
            raw = row.get(day, "")
            if pd.notna(raw):
                for p in str(raw).split():
                    t = PERIOD_MAP.get(p)
                    if dnum and t:
                        codes.append(f"{dnum}{t}")
        codes = sorted(codes, key=sort_key)

        course_map[name] = {
            'èª²è™Ÿ':       row['èª²è™Ÿ'],
            'æ•™å¸«':       row['æ•™å¸«'],
            'symbol':     symbol,
            'req':        info['req'],     # 'å¿…ä¿®' or 'é¸ä¿®'
            'detail':     info['detail'],  # e.g. 'æ ¡è¨‚å°ˆæ¥­å¿…ä¿®'
            'time_codes': codes
        }

    return label, course_map

def build_dept_info(class_urls, priority_dept=None):
    """    
    Arguments:
      class_urls: dict
        {
          "è³‡å·¥ç³»": { "è³‡å·¥ä¸€": url1, "è³‡å·¥äºŒ": url2, â€¦ },
          "é›»æ©Ÿç³»": { â€¦ },
          â€¦
        }
      priority_dept: str or Noneï¼Œä¾‹å¦‚ "è³‡å·¥ç³»"ã€‚è‹¥ä¸å‰‡ç‚º Noneï¼Œ
        å…ˆè®€è©²ç§‘ç³»ï¼Œå†è®€å…¶ä»–ç§‘ç³»ã€‚

    Returns:
      dept_info: list of (class_label, course_map)
    """
    dept_info = []

    # 1. å…ˆè™•ç† priority_deptï¼ˆè‹¥æœ‰æŒ‡å®šï¼‰
    if priority_dept and priority_dept in class_urls:
        for class_label, url in class_urls[priority_dept].items():
            print(f"æ­£åœ¨è®€å–ï¼ˆå„ªå…ˆï¼‰ï¼š{class_label}ï¼ˆ{url}ï¼‰")
            _, cmap = fetch_course_map(url)
            dept_info.append((class_label, cmap))

    # 2. è™•ç†å…¶ä»–ç§‘ç³»
    for dept, cls_dict in class_urls.items():
        if dept == priority_dept:
            continue
        for class_label, url in cls_dict.items():
            print(f"æ­£åœ¨è®€å–ï¼š{class_label}ï¼ˆ{url}ï¼‰")
            _, cmap = fetch_course_map(url)
            dept_info.append((class_label, cmap))

    return dept_info

def course_filter(dept_name, course_name, course_info):
    if "è³‡å·¥" in dept_name:
        return True
    elif course_name in ["é›»å­å­¸(ä¸€)","é›»å­å­¸(äºŒ)","é›»è·¯å­¸(ä¸€)","é›»è·¯å­¸(äºŒ)","ç·šæ€§ä»£æ•¸","æ©Ÿç‡","æ•¸ä½é‚è¼¯è¨­è¨ˆ","å¾®ç©åˆ†","é›¢æ•£æ•¸å­¸"]:
        return True
    else:
        return False


def try_schedule(name, dept_info, schedule, occupied, verbose=False):
    """
    name: èª²ç¨‹åç¨±
    dept_info: list of (label, course_map)
    """
    for label, cmap in dept_info:
        info = cmap.get(name)
        if not info:
            continue

        if not info['time_codes']:
            if verbose:
                print(f"â„¹ï¸ ã€{name}ã€åœ¨ã€{label}ã€æ²’æœ‰å›ºå®šä¸Šèª²æ™‚é–“")
            prev = schedule.at["NoTime", "ä¸€"]
            new = f"{name}({label})"
            schedule.at["NoTime", "ä¸€"] = (prev + "ï¼›" + new) if prev else new
            occupied[name] = name
            return True
        
        # filter rules 
        if not course_filter(label, name, info):
            if verbose:
                print(f"ğŸš« ã€{name}ã€åœ¨ã€{label}ã€ä¸ç¬¦åˆéæ¿¾è¦å‰‡ï¼Œè·³é")
            continue

        # è¡å ‚æª¢æŸ¥
        conflict = next((c for c in info['time_codes'] if c in occupied), None)
        if conflict:
            if verbose:
                print(f"âš ï¸ã€{name}ã€èˆ‡ã€{occupied[conflict]}ã€è¡å ‚æ–¼ {conflict}ï¼Œè·³é {label}")
            continue

        # ç„¡è¡å ‚å°±æ’
        for code in info['time_codes']:
            d, p = code[0], code[1]
            idx = int(p) if p.isdigit() else (10 if p=='a' else 11)
            col = DAY_NUM_TO_COL[d]
            schedule.at[idx, col] = f"{name}({label})"
            occupied[code] = name
        if verbose:
            print(f"âœ… å·²åœ¨ã€{label}ã€æ’å…¥ï¼š{name}")
        return True

    if verbose:
        print(f"âŒ ç„¡æ³•æ’å…¥ï¼š{name}")
    return False

if __name__ == "__main__":
    with open("class_urls_2.json", "r", encoding="utf-8") as f:
        class_urls = json.load(f)

    dept_info = build_dept_info(class_urls, priority_dept="è³‡å·¥ç³»")

    # initialize schedule
    cols     = ['ä¸€','äºŒ','ä¸‰','å››','äº”']
    periods  = list(range(1,12)) + ["NoTime"]
    schedule = pd.DataFrame('', index=periods, columns=cols)
    occupied = {}

    # é¸èª² piority
    selected = [
        "å¾®ç©åˆ†",
        "ä½œæ¥­ç³»çµ±",
        "å¯¦å‹™å°ˆé¡Œ(äºŒ)",
        "æ©Ÿç‡",
        "iOS æ‡‰ç”¨ç¨‹å¼é–‹ç™¼",
        "è‡ªç„¶èªè¨€è™•ç†èˆ‡æ–‡ä»¶æ¢å‹˜",
        "é§­å®¢æ”»é˜²æ¦‚è«–",
        "ç”Ÿæˆå¼äººå·¥æ™ºæ…§å°è«–"
    ]

# 5. æ’èª²
for name in selected:
    try_schedule(name, dept_info, schedule, occupied, verbose=True)

print("\n===== æœ€çµ‚æ’èª²è¡¨ =====")
clean = schedule.replace('', '-')  # ç©ºå€¼æ›æˆ '-'
print(tabulate(clean, headers="keys", showindex=True, tablefmt="grid"))



